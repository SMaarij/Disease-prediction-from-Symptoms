{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TRAINING(Random Forest Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest model\n",
    "from sklearn.preprocessing import LabelEncoder  # Label encoding for target variable\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix  # Evaluation metrics\n",
    "from sklearn.model_selection import train_test_split  # To split the dataset\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import seaborn as sns  # Data visualization library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df = pd.read_csv('Dataset\\\\training_data.csv')  # Read the training dataset\n",
    "df.head()  # Display the first few rows of the dataset to understand its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable\n",
    "encoder = LabelEncoder()  # Initialize the label encoder\n",
    "df['prognosis'] = encoder.fit_transform(df.prognosis)  # Encode the 'prognosis' column to convert categorical labels to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary column\n",
    "df = df.drop(['Unnamed: 133'], axis=1)  # Drop the 'Unnamed: 133' column, which is not needed for the analysis\n",
    "df.head()  # Display the first few rows of the dataset after dropping the column to verify changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlations\n",
    "df.corr()  # Calculate and display the correlation matrix to understand relationships between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()  # Check for missing values in each column to ensure data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df.iloc[:, :-1]  # Select all columns except the last one as features\n",
    "y = df.iloc[:, -1]  # Select the last column as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store accuracies\n",
    "max_depth_values = range(1, 21)\n",
    "training_accuracy_values = []\n",
    "validation_accuracy_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RandomForestClassifier with different max_depth values\n",
    "for max_depth in max_depth_values:\n",
    "    rfc = RandomForestClassifier(max_depth=max_depth, random_state=0)  # Initialize the Random Forest Classifier with max_depth\n",
    "    rfc.fit(X_train, y_train)  # Fit the model to the training data to train the classifier\n",
    "    train_acc = accuracy_score(y_train, rfc.predict(X_train))  # Calculate training accuracy\n",
    "    val_acc = accuracy_score(y_val, rfc.predict(X_val))  # Calculate validation accuracy\n",
    "    training_accuracy_values.append(train_acc)\n",
    "    validation_accuracy_values.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between max_depth and accuracy\n",
    "plt.plot(max_depth_values, training_accuracy_values, label=\"Train Accuracy\")\n",
    "plt.plot(max_depth_values, validation_accuracy_values, label=\"Validation Accuracy\")\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Relationship between max_depth and accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing data\n",
    "test = pd.read_csv('Dataset\\\\test_data.csv')  # Read the testing dataset\n",
    "test.head()  # Display the first few rows of the testing dataset to understand its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable in test data\n",
    "test['prognosis'] = encoder.transform(test.prognosis)  # Encode the 'prognosis' column in the test data to match training data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test features and target\n",
    "testx = test.iloc[:, :-1]  # Select all columns except the last one as features in the test data\n",
    "testy = test.iloc[:, -1]  # Select the last column as the target variable in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the trained model with optimal max_depth\n",
    "optimal_rfc = RandomForestClassifier(max_depth=10, random_state=0)  # Using max_depth=10\n",
    "optimal_rfc.fit(X_train, y_train)\n",
    "y_pred = optimal_rfc.predict(testx)  # Predict the target variable for the test data using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(f\"Accuracy on train data by Random Forest Classifier: {accuracy_score(y_train, optimal_rfc.predict(X_train)) * 100:.2f}%\")  # Print the accuracy on the training data to evaluate model performance\n",
    "print(f\"Accuracy on test data by Random Forest Classifier: {accuracy_score(testy, y_pred) * 100:.2f}%\")  # Print the accuracy on the test data to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cf_matrix = confusion_matrix(testy, y_pred)  # Compute the confusion matrix to understand the performance of the classifier\n",
    "plt.figure(figsize=(12, 8))  # Set the figure size for the plot\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d')  # Plot the confusion matrix with annotations to visualize the results\n",
    "plt.title(\"Confusion Matrix for Random Forest Classifier on Test Data\")  # Set the title of the plot for clarity\n",
    "plt.show()  # Display the plot to visualize the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier Without Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 0\n",
      "Feature matrix shape: (4920, 132), Target vector shape: (4920,)\n",
      "Accuracy: 21.54%\n",
      "Cross-validation accuracy: 28.25%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\NEDUET\\Documents\\GitHub\\Disease-prediction-from-Symptoms\\Notebook\\Dataset\\training_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()\n",
    "\n",
    "# Drop the unnecessary column\n",
    "data = data.drop(columns=['Unnamed: 133'])\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum().sum()\n",
    "print(f'Missing values: {missing_values}')\n",
    "\n",
    "# Encode the target variable 'prognosis'\n",
    "label_encoder = LabelEncoder()\n",
    "data['prognosis'] = label_encoder.fit_transform(data['prognosis'])\n",
    "\n",
    "# Prepare the feature matrix (X) and target vector (y)\n",
    "X = data.drop(columns=['prognosis']).values\n",
    "y = data['prognosis'].values\n",
    "\n",
    "print(f'Feature matrix shape: {X.shape}, Target vector shape: {y.shape}')\n",
    "\n",
    "def gini_impurity(y):\n",
    "    \"\"\"Calculate the Gini Impurity for a list of labels.\"\"\"\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "    impurity = 1.0\n",
    "    for count in class_counts:\n",
    "        prob_of_class = count / len(y)\n",
    "        impurity -= prob_of_class ** 2\n",
    "    return impurity\n",
    "\n",
    "def split_data(X, y, feature_index, threshold):\n",
    "    \"\"\"Split the dataset based on a feature and threshold.\"\"\"\n",
    "    left_mask = X[:, feature_index] <= threshold\n",
    "    right_mask = X[:, feature_index] > threshold\n",
    "    return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "def best_split(X, y):\n",
    "    \"\"\"Find the best feature and threshold to split the data.\"\"\"\n",
    "    best_gini = float('inf')\n",
    "    best_feature_index = None\n",
    "    best_threshold = None\n",
    "    for feature_index in range(X.shape[1]):\n",
    "        thresholds = np.unique(X[:, feature_index])\n",
    "        for threshold in thresholds:\n",
    "            X_left, X_right, y_left, y_right = split_data(X, y, feature_index, threshold)\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "            gini_left = gini_impurity(y_left)\n",
    "            gini_right = gini_impurity(y_right)\n",
    "            gini = (len(y_left) * gini_left + len(y_right) * gini_right) / len(y)\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "    return best_feature_index, best_threshold\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        if num_samples <= 1 or depth == self.max_depth:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return leaf_value\n",
    "\n",
    "        feature_index, threshold = best_split(X, y)\n",
    "        if feature_index is None:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return leaf_value\n",
    "\n",
    "        X_left, X_right, y_left, y_right = split_data(X, y, feature_index, threshold)\n",
    "        if len(y_left) == 0 or len(y_right) == 0:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return leaf_value\n",
    "\n",
    "        left_subtree = self.fit(X_left, y_left, depth + 1)\n",
    "        right_subtree = self.fit(X_right, y_right, depth + 1)\n",
    "        self.tree = (feature_index, threshold, left_subtree, right_subtree)\n",
    "        return self.tree\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(inputs, self.tree) for inputs in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, inputs, tree):\n",
    "        if not isinstance(tree, tuple):\n",
    "            return tree\n",
    "        feature_index, threshold, left_subtree, right_subtree = tree\n",
    "        if inputs[feature_index] <= threshold:\n",
    "            return self._predict(inputs, left_subtree)\n",
    "        else:\n",
    "            return self._predict(inputs, right_subtree)\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the decision tree model\n",
    "tree = DecisionTree(max_depth=10)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Perform cross-validation to get the average accuracy\n",
    "def cross_val_score_custom(model, X, y, cv=5):\n",
    "    fold_size = len(X) // cv\n",
    "    scores = []\n",
    "    for i in range(cv):\n",
    "        X_val = X[i*fold_size:(i+1)*fold_size]\n",
    "        y_val = y[i*fold_size:(i+1)*fold_size]\n",
    "        X_train = np.concatenate([X[:i*fold_size], X[(i+1)*fold_size:]])\n",
    "        y_train = np.concatenate([y[:i*fold_size], y[(i+1)*fold_size:]])\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "    return scores\n",
    "\n",
    "# Evaluate the model using custom cross-validation\n",
    "cv_scores = cross_val_score_custom(DecisionTree(max_depth=10), X, y, cv=5)\n",
    "print(f'Cross-validation accuracy: {np.mean(cv_scores) * 100:.2f}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
